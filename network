# Network Policy
- Kubernetes가 지원하는 pod 통신 접근제한
- 일종의 방화벽으로 pod로 트래픽이 들어오고(inbound), 나가는(outbound) 것을 설정하는 정책

- ingress 트래픽 : inbound 정책. 들어오는 트래픽을 허용할 것인지를 정의
- egress 트래픽 : outbound 정책. 트래픽이 나갈 수 있는 허용 범위 정의

트래픽 컨트롤 정의
- ipBlock : CIDR IP 대역으로 특정 IP 대역에서만 트래픽이 들어오도록 지정할 수 있다
- podSelector : label을 이용하여 특정 label을 가지고 있는 pod들에서 들어오는 트래픽만 받을 수 있다. 예를 들어 DB Pod의 경우에는 API server로부터 들어오는 트래픽만 받는 것과 같은 정책 정의가 가능하다
- namespaceSelector : 특정 namespace로부터 들어오는 트래픽만을 받는 기능이다. 운영 로깅 서버의 경우에는 운영 환경 namespace에서만 들어오는 트래픽을 받거나 특정 서비스 컴포넌트의 namespace에서의 트래픽만 들어오게 컨트롤이 가능하다. 내부적으로 새로운 서비스 컨포넌트를 오픈했을 때 베타 서비스를 위해서 특정 서비스나 팀에게만 서비스를 오픈하고자 할 때 유용하게 사용할 수 있다.
- protocol & port : 특정 protocol 또는 port로 설정된 트래픽만 허용되는 포트를 정의할 수 있다.

# LAB(network policy : CNI가 지원해줘야 쓸 수 있음)
- app : web 레이블을 가진 Pod에 특정 namespace의 pod들만 접근 허용

$ kubectl config use-context hk8s
$ kubectl run webpod --image=nginx --port=80 --labels=app=web
$ kubectl get pods webpod -o wide

$ kubectl create namespace dev
$ kubectl create namespace prod
$ kubectl label namespace prod purpose=production
$ kubectl label namespace dev purpose=development
$ kubectl get namespaces --show-labels
$ kubectl get namespaces --show-labels

$ vi web-allow-prod.yaml
https://kubernetes.io/docs/tasks/administer-cluster/declare-network-policy/

apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: web-allow-prod
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: web
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          pusrpose: production
    ports:
    - protocol: TCP
      port: 80


$ kubectl apply -f web-allow-prod.yaml
$ kubectl get networkpolicies.networking.k8s.io
$ kubectl describe networkpolicies.networking.k8s.io

$ kubectl run test --namespace=dev --rm -it --image=alpine -- /bin/sh
$ kubectl run test -n dev --rm -it --image=centos:7 dev -- /bin/bash

/ # wget -qO --timeout=2 http://web.default.svc.cluster.local
$ kubectl run test --namesapce=prod --rm -it --image=alpine -- /bin/sh
/ # wget -qO --timeout=2 http://web.default.svc.cluster.local

$ kubectl delete networkpolicy web-allow-prod
$ kubectl delete pod webpod
$ kubectl delete namespace {prod,dev}


# 문제
- NetworkPolicy
- 작업 클러스터 : hk8s
- default namespace에 다음과 같은 pod를 생성하세요
- name: poc
- image: nginx
- port : 80
- label: app=poc
- 'partition=customera'를 사용하는 namespace에서만 poc의 80 포트로 연결할 수 있도록 default namespace에 'allow-web-from-customera'라는 network policy를 설정하세요. 보안 정책상 다른 namespace의 접근은 제한합니다.

$ kubectl config use-context hk8s
$ kubectl run poc --image=nginx --port=80 --labels=app=poc

$ kubectl get pod poc -o wide

$ kubectl get namespaces

$ kubectl get namespaces -L partition

$ vi allow-web-from-customera.yaml
https://kubernetes.io/docs/concepts/services-networking/network-policies/


apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-web-from-customera
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: poc
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          partition: customera
    ports:
    - protocol: TCP
      port: 80


$ kubectl apply -f allow-web-from-customera.yaml

$ kubectl run test --image=centos:7 -it --rm -n customera -- /bin/bash

/ #curl 192.168.75.105


# Ingress
- L7 스위치 역할을 논리적으로 수행
- 클러스터로 접근하는 URL별로 다른 서비스에 트래픽을 분산
- k8s ingress 기능
-- service에 외부 url을 제공
-- 트래픽을 로드밸런싱
-- ssl 인증서 처리
-- virtual hosting을 지정

# 문제
- ingress 구성
- 작업 클러스터 : k8s
- ingress-nginx namespace에 nginx 이미지를 app=nginx 레이블을 가지고 실행하는 nginx pod를 구성하세요
- 현재 appjs-service와 nginx 서비스는 이미 동작 중입니다. 별도 구성이 필요합니다.

- app-ingress.yaml 파일을 생성하고 다음 조건의 ingress를 구성하세요
- name: app-ingress
- NODE_PORT:30080/ 접속했을 때 nginx 서비스로 연결
- NODE_PORT:30080/app 접속했을 때 appjs-service 서비스로 연결
- ingress 구성에 다음의 annotations을 포함시키세요
  annotations:
   kubernetes.io/ingress.class: nginx


$ kubectl run nginx --image=nginx --labels=app=nginx --dry-run=client -o yaml 

$ kubectl run nginx --image=nginx --labels=app=nginx -n ingress-nginx --dry-run=client -o yaml

$ kubectl get pod -n ingress-nginx -L app

$ kubectl get svc -n ingress-nginx

$ vi app-ingress.yaml
https://kubernetes.io/docs/concepts/services-networking/ingress/

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  namespace: ingress-nginx
  name: app-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx
            port:
              number: 80
      - path: /app
        pathType: Prefix
        backend:
          service:
            name: appjs-service
            port:
              number: 80

$ kubectl apply -f app-ingress.yaml

$ kubectl get ingress -n ingress-nginx

$ kubectl describe ingress -n ingress-nginx app-ingress
$ curl k8s-worker2:30080/app


# CoreDNS
- 쿠버네티스 클러스터에서 사용하는 DNS
- 클러스터 내의 모든 service에는 dns 네임이 할당된다
- 클러스터에서 동작되는 모든 pod의 /etc/resolv.conf 에는 kube-dns가 namespace로 정의되어 있다
- 특정 pod에서 service name이나 pod name으로 access 가능

- FQDN : Full Qualitied Domain Name

# LAB
- 간단한 web deployment 생성 후 service 구성
- 다른 pod에서 name 조회할 수 있는지 테스트

$ kubectl config use-context k8s
$ kubectl create deployment web --image=nginx --port 80 --replicas=2
$ kubectl expose deployment web --port 80
$ kubectl get deployments.apps,svc

$ kubectl run dns-test --image=busybox -it --rm -- /bin/sh
/# cat /etc/resolv.conf
/# nslookup 10.96.0.10


# 문제
- 작업 클러스터 : k8s
- image nginx를 사용하는 resolver pod를 생성하고 resolver-service라는 service를 구성합니다.

$ kubectl run resolver --image=nginx 
$ kubectl expose pod resolver --port 80 --name=resolver-service
$ kubectl get pod resolver
$ kubectl get pod resolver -o wide
$ kubectl get svc resolver-service




- 클러스터 내에서 service와 pod 이름을 조회할 수 있는지 테스트합니다.
- dns 조회에 사용하는 pod 이미지는 busybox이고 service와 pod 이름 조회는 nslookup을 사용합니다.
- service 조회 결과는 /var/CKA2022/nginx.svc에 pod name 조회 결과는 /var/CKA2022/nginx.pod 파일에 기록합니다.


$ kubectl run test --image=busybox -it --rm -- /bin/sh
/# nslookup 10-244-1-46.default.pod.cluster.local
/# nslookup 10.106.20.222

/# nslookup resolver-service

- resolver: 10.244.1.46 > /var/CKA2022/nginx.pod
  nslookup 10-244-1-46.default.pod.cluster.local


- resolver-service : 
  nslookup 10.106.20.222 > /var/CKA2022/nginx.svc

$ cat /var/CKA2022/nginx.pod
$ cat /var/CKA2022/nginx.svc 